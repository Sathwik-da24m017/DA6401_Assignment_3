{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T21:18:31.746579Z",
     "iopub.status.busy": "2025-04-26T21:18:31.746382Z",
     "iopub.status.idle": "2025-04-26T21:18:31.755555Z",
     "shell.execute_reply": "2025-04-26T21:18:31.754518Z",
     "shell.execute_reply.started": "2025-04-26T21:18:31.746560Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configurations\n",
    "\n",
    "class Config:\n",
    "    # Model parameters\n",
    "    embedding_dim = 256\n",
    "    hidden_dim = 512\n",
    "    encoder_layers = 1\n",
    "    decoder_layers = 1\n",
    "    cell_type = 'LSTM'  # Options: 'RNN', 'LSTM', 'GRU'\n",
    "    \n",
    "    # Training parameters\n",
    "    batch_size = 64\n",
    "    num_epochs = 20\n",
    "    learning_rate = 0.001\n",
    "    teacher_forcing_ratio = 0.5\n",
    "    \n",
    "    # Data parameters\n",
    "    max_input_length = 30\n",
    "    max_output_length = 30\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T21:21:33.211786Z",
     "iopub.status.busy": "2025-04-26T21:21:33.211434Z",
     "iopub.status.idle": "2025-04-26T21:21:37.613442Z",
     "shell.execute_reply": "2025-04-26T21:21:37.612601Z",
     "shell.execute_reply.started": "2025-04-26T21:21:33.211760Z"
    }
   },
   "outputs": [],
   "source": [
    "# Encoder Model\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, num_layers=1, cell_type='LSTM'):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        \n",
    "        if cell_type == 'RNN':\n",
    "            self.rnn = nn.RNN(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        elif cell_type == 'GRU':\n",
    "            self.rnn = nn.GRU(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        elif cell_type == 'LSTM':\n",
    "            self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown RNN cell type: {cell_type}\")\n",
    "        \n",
    "        self.cell_type = cell_type\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src shape: (batch_size, src_len)\n",
    "        embedded = self.embedding(src)  # (batch_size, src_len, embedding_dim)\n",
    "        \n",
    "        outputs, hidden = self.rnn(embedded)  # outputs: (batch_size, src_len, hidden_dim)\n",
    "        \n",
    "        # hidden: for LSTM, it's a tuple (hidden_state, cell_state)\n",
    "        return outputs, hidden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T21:22:08.042613Z",
     "iopub.status.busy": "2025-04-26T21:22:08.042212Z",
     "iopub.status.idle": "2025-04-26T21:22:08.050858Z",
     "shell.execute_reply": "2025-04-26T21:22:08.050033Z",
     "shell.execute_reply.started": "2025-04-26T21:22:08.042589Z"
    }
   },
   "outputs": [],
   "source": [
    "# Decoder Model\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, embedding_dim, hidden_dim, num_layers=1, cell_type='LSTM'):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
    "        \n",
    "        if cell_type == 'RNN':\n",
    "            self.rnn = nn.RNN(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        elif cell_type == 'GRU':\n",
    "            self.rnn = nn.GRU(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        elif cell_type == 'LSTM':\n",
    "            self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown RNN cell type: {cell_type}\")\n",
    "        \n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        self.cell_type = cell_type\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # input shape: (batch_size)\n",
    "        input = input.unsqueeze(1)  # (batch_size, 1)\n",
    "        \n",
    "        embedded = self.embedding(input)  # (batch_size, 1, embedding_dim)\n",
    "        \n",
    "        output, hidden = self.rnn(embedded, hidden)  # output: (batch_size, 1, hidden_dim)\n",
    "        \n",
    "        prediction = self.fc_out(output.squeeze(1))  # (batch_size, output_dim)\n",
    "        \n",
    "        return prediction, hidden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2Seq wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T21:22:29.652087Z",
     "iopub.status.busy": "2025-04-26T21:22:29.651767Z",
     "iopub.status.idle": "2025-04-26T21:22:29.660029Z",
     "shell.execute_reply": "2025-04-26T21:22:29.659076Z",
     "shell.execute_reply.started": "2025-04-26T21:22:29.652061Z"
    }
   },
   "outputs": [],
   "source": [
    "# Seq2Seq Model\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device, teacher_forcing_ratio=0.5):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "\n",
    "        assert encoder.hidden_dim == decoder.hidden_dim, \"Encoder and Decoder hidden dimensions must match!\"\n",
    "        assert encoder.num_layers == decoder.num_layers, \"Encoder and Decoder must have same number of layers!\"\n",
    "        assert encoder.cell_type == decoder.cell_type, \"Encoder and Decoder must have same RNN cell type!\"\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing=True):\n",
    "        \"\"\"\n",
    "        src: source sequences (batch_size, src_len)\n",
    "        trg: target sequences (batch_size, trg_len)\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size = src.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "        output_dim = self.decoder.fc_out.out_features\n",
    "\n",
    "        # Tensor to store decoder outputs\n",
    "        outputs = torch.zeros(batch_size, trg_len, output_dim).to(self.device)\n",
    "\n",
    "        # Encode the source sequence\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "\n",
    "        # First input to the decoder is the <sos> tokens (start of sequence)\n",
    "        input = trg[:, 0]\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden = self.decoder(input, hidden)\n",
    "            outputs[:, t] = output\n",
    "\n",
    "            # Decide whether to do teacher forcing\n",
    "            if teacher_forcing and (torch.rand(1).item() < self.teacher_forcing_ratio):\n",
    "                input = trg[:, t]  # use actual next token\n",
    "            else:\n",
    "                input = output.argmax(1)  # use predicted token\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T21:23:06.304772Z",
     "iopub.status.busy": "2025-04-26T21:23:06.304060Z",
     "iopub.status.idle": "2025-04-26T21:23:06.650075Z",
     "shell.execute_reply": "2025-04-26T21:23:06.649075Z",
     "shell.execute_reply.started": "2025-04-26T21:23:06.304744Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data Loading\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class DakshinaDataset(Dataset):\n",
    "    def __init__(self, data_path, input_tokenizer, output_tokenizer, max_input_len=30, max_output_len=30):\n",
    "        \"\"\"\n",
    "        data_path: path to the dataset CSV or TXT file\n",
    "        input_tokenizer: tokenizer for Latin script\n",
    "        output_tokenizer: tokenizer for Devanagari script\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(data_path, sep='\\t', header=None, names=['latin', 'devanagari'])\n",
    "        \n",
    "        self.input_tokenizer = input_tokenizer\n",
    "        self.output_tokenizer = output_tokenizer\n",
    "        self.max_input_len = max_input_len\n",
    "        self.max_output_len = max_output_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        latin_word = self.data.iloc[idx]['latin']\n",
    "        devanagari_word = self.data.iloc[idx]['devanagari']\n",
    "\n",
    "        input_seq = self.input_tokenizer.text_to_sequence(latin_word, self.max_input_len)\n",
    "        output_seq = self.output_tokenizer.text_to_sequence(devanagari_word, self.max_output_len)\n",
    "\n",
    "        return {\n",
    "            'input': torch.tensor(input_seq, dtype=torch.long),\n",
    "            'target': torch.tensor(output_seq, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Helper class for tokenizing characters\n",
    "class CharTokenizer:\n",
    "    def __init__(self, texts):\n",
    "        self.char2idx = {'<pad>': 0, '<sos>': 1, '<eos>': 2}\n",
    "        self.idx2char = {0: '<pad>', 1: '<sos>', 2: '<eos>'}\n",
    "        \n",
    "        idx = 3\n",
    "        for text in texts:\n",
    "            for ch in text:\n",
    "                if ch not in self.char2idx:\n",
    "                    self.char2idx[ch] = idx\n",
    "                    self.idx2char[idx] = ch\n",
    "                    idx += 1\n",
    "\n",
    "    def text_to_sequence(self, text, max_len):\n",
    "        seq = [self.char2idx.get(ch, 0) for ch in text]  # Unknown characters go to <pad> (0)\n",
    "        seq = [self.char2idx['<sos>']] + seq + [self.char2idx['<eos>']]\n",
    "        \n",
    "        if len(seq) < max_len:\n",
    "            seq += [self.char2idx['<pad>']] * (max_len - len(seq))\n",
    "        else:\n",
    "            seq = seq[:max_len]\n",
    "        \n",
    "        return seq\n",
    "\n",
    "    def sequence_to_text(self, sequence):\n",
    "        return ''.join([self.idx2char.get(idx, '') for idx in sequence if idx not in [0, 1, 2]])\n",
    "\n",
    "    def vocab_size(self):\n",
    "        return len(self.char2idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T21:23:27.137268Z",
     "iopub.status.busy": "2025-04-26T21:23:27.136802Z",
     "iopub.status.idle": "2025-04-26T21:23:27.143872Z",
     "shell.execute_reply": "2025-04-26T21:23:27.142993Z",
     "shell.execute_reply.started": "2025-04-26T21:23:27.137242Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "def train(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        src = batch['input'].to(device)    # (batch_size, src_len)\n",
    "        trg = batch['target'].to(device)    # (batch_size, trg_len)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(src, trg)  # output shape: (batch_size, trg_len, output_dim)\n",
    "        \n",
    "        # reshape to calculate loss\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[:, 1:].reshape(-1, output_dim)   # skip <sos> for output\n",
    "        trg = trg[:, 1:].reshape(-1)                     # skip <sos> for target\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T21:23:46.007105Z",
     "iopub.status.busy": "2025-04-26T21:23:46.006782Z",
     "iopub.status.idle": "2025-04-26T21:23:46.013288Z",
     "shell.execute_reply": "2025-04-26T21:23:46.012293Z",
     "shell.execute_reply.started": "2025-04-26T21:23:46.007084Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            src = batch['input'].to(device)\n",
    "            trg = batch['target'].to(device)\n",
    "            \n",
    "            output = model(src, trg, teacher_forcing=False)  # No teacher forcing during eval\n",
    "            \n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[:, 1:].reshape(-1, output_dim)\n",
    "            trg = trg[:, 1:].reshape(-1)\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wandb logging setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T21:24:31.034674Z",
     "iopub.status.busy": "2025-04-26T21:24:31.034107Z",
     "iopub.status.idle": "2025-04-26T21:24:34.136920Z",
     "shell.execute_reply": "2025-04-26T21:24:34.136113Z",
     "shell.execute_reply.started": "2025-04-26T21:24:31.034644Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/sathwikpentela/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mda24m017\u001b[0m (\u001b[33mda24m017-indian-institute-of-technology-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "# wandb Setup\n",
    "\n",
    "import wandb\n",
    "wandb.login(key='f56388c51b488c425a228537fd2d35e5498a3a91')\n",
    "def init_wandb(project_name, config):\n",
    "    wandb.init(\n",
    "        project=project_name,\n",
    "        config={\n",
    "            \"embedding_dim\": config.embedding_dim,\n",
    "            \"hidden_dim\": config.hidden_dim,\n",
    "            \"encoder_layers\": config.encoder_layers,\n",
    "            \"decoder_layers\": config.decoder_layers,\n",
    "            \"cell_type\": config.cell_type,\n",
    "            \"batch_size\": config.batch_size,\n",
    "            \"learning_rate\": config.learning_rate,\n",
    "            \"teacher_forcing_ratio\": config.teacher_forcing_ratio,\n",
    "            \"max_input_length\": config.max_input_length,\n",
    "            \"max_output_length\": config.max_output_length\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Run\n",
    "\n",
    "# 1. Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 2. Initialize config\n",
    "config = Config()\n",
    "\n",
    "# 3. Load dataset\n",
    "train_data_path = 'dakshina_dataset_v1.0/hi/lexicons/romanized_train.tsv'\n",
    "val_data_path = 'dakshina_dataset_v1.0/hi/lexicons/romanized_val.tsv'\n",
    "\n",
    "# First, gather all characters for tokenizers\n",
    "train_df = pd.read_csv(train_data_path, sep='\\t', header=None, names=['latin', 'devanagari'])\n",
    "val_df = pd.read_csv(val_data_path, sep='\\t', header=None, names=['latin', 'devanagari'])\n",
    "\n",
    "input_texts = train_df['latin'].tolist()\n",
    "output_texts = train_df['devanagari'].tolist()\n",
    "\n",
    "input_tokenizer = CharTokenizer(input_texts)\n",
    "output_tokenizer = CharTokenizer(output_texts)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = DakshinaDataset(train_data_path, input_tokenizer, output_tokenizer, config.max_input_length, config.max_output_length)\n",
    "val_dataset = DakshinaDataset(val_data_path, input_tokenizer, output_tokenizer, config.max_input_length, config.max_output_length)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config.batch_size)\n",
    "\n",
    "# 4. Initialize models\n",
    "encoder = Encoder(\n",
    "    input_dim=input_tokenizer.vocab_size(),\n",
    "    embedding_dim=config.embedding_dim,\n",
    "    hidden_dim=config.hidden_dim,\n",
    "    num_layers=config.encoder_layers,\n",
    "    cell_type=config.cell_type\n",
    ")\n",
    "\n",
    "decoder = Decoder(\n",
    "    output_dim=output_tokenizer.vocab_size(),\n",
    "    embedding_dim=config.embedding_dim,\n",
    "    hidden_dim=config.hidden_dim,\n",
    "    num_layers=config.decoder_layers,\n",
    "    cell_type=config.cell_type\n",
    ")\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device, config.teacher_forcing_ratio).to(device)\n",
    "\n",
    "# 5. Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)  # ignore padding index\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "# 6. Initialize wandb\n",
    "init_wandb(project_name=\"seq2seq-dakshina\", config=config)\n",
    "\n",
    "# 7. Training loop\n",
    "for epoch in range(config.num_epochs):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss = evaluate(model, val_loader, criterion, device)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{config.num_epochs}] Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    # Log to wandb\n",
    "    wandb.log({\"train_loss\": train_loss, \"val_loss\": val_loss})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
